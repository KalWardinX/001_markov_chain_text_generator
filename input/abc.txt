computer science, the study of computers and computing,
 including their theoretical and algorithmic foundations,
 hardware and software, and their uses for processing information.
 The discipline of computer science includes the study of algorithms and 
 data structures, computer and network design, modeling data and information 
 processes, and artificial intelligence. Computer science draws some of its 
 foundations from mathematics and engineering and therefore incorporates 
 techniques from areas such as queueing theory, probability and statistics, 
 and electronic circuit design. Computer science also makes heavy use of 
 hypothesis testing and experimentation during the conceptualization, design,
  measurement, and refinement of new algorithms, information structures, 
  and computer architectures.

Computer science is considered as part of a family of five separate yet 
interrelated disciplines: computer engineering, computer science, information 
systems, information technology, and software engineering. This family has come 
to be known collectively as the discipline of computing. These five disciplines 
are interrelated in the sense that computing is their object of study, but they 
are separate since each has its own research perspective and curricular focus. 
(Since 1991 the Association for Computing Machinery [ACM], the IEEE Computer 
Society [IEEE-CS], and the Association for Information Systems [AIS] have 
collaborated to develop and update the taxonomy of these five interrelated 
disciplines and the guidelines that educational institutions worldwide use for 
their undergraduate, graduate, and research programs.)

The major subfields of computer science include the traditional study of 
computer architecture, programming languages, and software development. However,
they also include computational science (the use of algorithmic techniques 
for modeling scientific data), graphics and visualization, human-computer 
interaction, databases and information systems, networks, and the social and 
professional issues that are unique to the practice of computer science. As may 
be evident, some of these subfields overlap in their activities with other 
modern fields, such as bioinformatics and computational chemistry. These 
overlaps are the consequence of a tendency among computer scientists to 
recognize and act upon their field’s many interdisciplinary connections.

Computer science emerged as an independent discipline in the early 1960s, 
although the electronic digital computer that is the object of its study was 
invented some two decades earlier. The roots of computer science lie primarily 
in the related fields of mathematics, electrical engineering, physics, and 
management information systems.

Mathematics is the source of two key concepts in the development of the 
computer—the idea that all information can be represented as sequences of zeros 
and ones and the abstract notion of a “stored program.” In the binary number 
system, numbers are represented by a sequence of the binary digits 0 and 1 in 
the same way that numbers in the familiar decimal system are represented using 
the digits 0 through 9. The relative ease with which two states (e.g., high and 
low voltage) can be realized in electrical and electronic devices led naturally 
to the binary digit, or bit, becoming the basic unit of data storage and 
transmission in a computer system.

Electrical engineering provides the basics of circuit design—namely, the idea 
that electrical impulses input to a circuit can be combined using Boolean 
algebra to produce arbitrary outputs. (The Boolean algebra developed in the 
19th century supplied a formalism for designing a circuit with binary input 
values of zeros and ones [false or true, respectively, in the terminology of 
logic] to yield any desired combination of zeros and ones as output.) The 
invention of the transistor and the miniaturization of circuits, along with 
the invention of electronic, magnetic, and optical media for the storage and 
transmission of information, resulted from advances in electrical engineering 
and physics.

Management information systems, originally called data processing systems, 
provided early ideas from which various computer science concepts such as 
sorting, searching, databases, information retrieval, and graphical user 
interfaces evolved. Large corporations housed computers that stored information 
that was central to the activities of running a business—payroll, accounting, 
inventory management, production control, shipping, and receiving.

Theoretical work on computability, which began in the 1930s, provided the needed
 extension of these advances to the design of whole machines; a milestone was 
 the 1936 specification of the Turing machine (a theoretical computational model
  that carries out instructions represented as a series of zeros and ones) by 
  the British mathematician Alan Turing and his proof of the model’s 
  computational power. Another breakthrough was the concept of the 
  stored-program computer, usually credited to Hungarian American mathematician
   John von Neumann. These are the origins of the computer science field that
    later became known as architecture and organization.

In the 1950s, most computer users worked either in scientific research 
labs or in large corporations. The former group used computers to help them make
 complex mathematical calculations (e.g., missile trajectories), while the latter
  group used computers to manage large amounts of corporate data (e.g., payrolls
   and inventories). Both groups quickly learned that writing programs in the 
   machine language of zeros and ones was not practical or reliable. This 
   discovery led to the development of assembly language in the early 1950s, 
   which allows programmers to use symbols for instructions (e.g., ADD for
    addition) and variables (e.g., X). Another program, known as an assembler,
     translated these symbolic programs into an equivalent binary program whose 
     steps the computer could carry out, or “execute.”

Other system software elements known as linking loaders were developed to 
combine pieces of assembled code and load them into the computer’s memory, 
where they could be executed. The concept of linking separate pieces of code
 was important, since it allowed “libraries” of programs for carrying out common 
 to be reused. This was a first step in the development of the computer science 
 field called software engineering.

Later in the 1950s, assembly language was found to be so cumbersome that the 
development of high-level languages (closer to natural languages) began to 
support easier, faster programming. FORTRAN emerged as the main high-level 
language for scientific programming, while COBOL became the main language for 
business programming. These languages carried with them the need for different
 software, called compilers, that translate high-level language programs into
  machine code. As programming languages became more powerful and abstract,
   building compilers that create high-quality machine code and that are 
   efficient in terms of execution speed and storage consumption became a 
challenging computer science problem. The design and implementation of 
high-level languages is at the heart of the computer science field called
 programming languages.


Increasing use of computers in the early 1960s provided the impetus for the 
development of the first operating systems, which consisted of system-resident 
software that automatically handled input and output and the execution of 
programs called “jobs.” The demand for better computational techniques led to 
a resurgence of interest in numerical methods and their analysis, an activity 
that expanded so widely that it became known as computational science.

The 1970s and ’80s saw the emergence of powerful computer graphics devices, 
both for scientific modeling and other visual activities. 
(Computerized graphical devices were introduced in the early 1950s with the 
display of crude images on paper plots and cathode-ray tube [CRT] screens.) 
Expensive hardware and the limited availability of software kept the field 
from growing until the early 1980s, when the computer memory required for 
bitmap graphics (in which an image is made up of small rectangular pixels) 
became more affordable. Bitmap technology, together with high-resolution 
display screens and the development of graphics standards that make software 
less machine-dependent, has led to the explosive growth of the field. Support 
for all these activities evolved into the field of computer science known as 
graphics and visual computing.

Closely related to this field is the design and analysis of systems that 
interact directly with users who are carrying out various computational 
tasks. These systems came into wide use during the 1980s and ’90s, when 
line-edited interactions with users were replaced by graphical user interfaces 
(GUIs). GUI design, which was pioneered by Xerox and was later picked up by 
Apple (Macintosh) and finally by Microsoft (Windows), is important because it 
constitutes what people see and do when they interact with a computing device. 
The design of appropriate user interfaces for all types of users has evolved 
into the computer science field known as human-computer interaction (HCI).
